# ============================================
# Graph RAG - Docker 部署环境变量
# ============================================
# 使用方法: 复制此文件为 .env 并修改配置
#   cp .env.docker.example .env
# ============================================

# ---- 端口映射 ----
BACKEND_PORT=8008
FRONTEND_PORT=3000
NEBULA_GRAPHD_PORT=9669
NEBULA_STUDIO_PORT=7001
QDRANT_PORT=6333

# ---- 应用设置 ----
APP_NAME=Graph RAG
DEBUG=false
HOST=0.0.0.0
PORT=8008

# ---- NebulaGraph 设置 ----
# Docker 环境下自动使用内部网络地址，无需修改
NEBULA__HOSTS=["nebula-graphd:9669"]
NEBULA__USERNAME=root
NEBULA__PASSWORD=nebula
NEBULA__SPACE=graph_rag
NEBULA__MAX_CONNECTION_POOL_SIZE=10

# ---- Vector Store 设置 ----
# Docker 环境下自动使用内部网络地址，无需修改
VECTOR_STORE__TYPE=qdrant
VECTOR_STORE__QDRANT_HOST=qdrant
VECTOR_STORE__QDRANT_PORT=6333
VECTOR_STORE__QDRANT_COLLECTION=graph_rag
VECTOR_STORE__DIMENSION=1536

# ---- Embedding 设置 (必填) ----
EMBEDDING__TYPE=openai
EMBEDDING__OPENAI_MODEL=text-embedding-ada-002
EMBEDDING__OPENAI_API_KEY=your-openai-api-key
EMBEDDING__OPENAI_API_BASE=https://api.openai.com/v1

# ---- LLM 设置 (必填) ----
LLM__TYPE=openai
LLM__OPENAI_MODEL=gpt-4o-mini
LLM__TEMPERATURE=0.7
LLM__MAX_TOKENS=2048
LLM__OPENAI_API_KEY=your-openai-api-key
LLM__OPENAI_API_BASE=https://api.openai.com/v1

# ---- Ollama 设置 (如使用 Ollama) ----
# 如果使用本机 Ollama，需要将 host.docker.internal 替换 localhost
# LLM__TYPE=ollama
# LLM__OLLAMA_HOST=http://host.docker.internal:11434
# LLM__OLLAMA_MODEL=llama3.2
